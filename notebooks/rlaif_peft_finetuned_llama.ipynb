{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Uninstall conflicting packages to start clean\n",
        "!pip uninstall -y torch torchvision transformers accelerate bitsandbytes unsloth\n",
        "\n",
        "# Install PyTorch and Torchvision with compatible versions\n",
        "!pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Install Transformers with a specific compatible version\n",
        "!pip install transformers==4.46.2\n",
        "\n",
        "# Install Accelerate (compatible with transformers, trl, and peft)\n",
        "!pip install accelerate>=0.34.1\n",
        "\n",
        "# Install bitsandbytes for 4-bit/8-bit quantization\n",
        "!pip install bitsandbytes==0.43.3\n",
        "\n",
        "# Install Unsloth\n",
        "!pip install unsloth==2024.11.7\n",
        "\n",
        "# Optional: Install dotenv if needed for environment variable management\n",
        "!pip install python-dotenv\n",
        "\n",
        "# Install TRL and related packages with compatible versions\n",
        "!pip install \"trl<0.9.0\" peft nltk tqdm groq\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T8WoIrKMNro",
        "outputId": "e8e7f0e1-c5fc-447b-f076-85c1f391dda0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.1\n",
            "Uninstalling torch-2.5.1:\n",
            "  Successfully uninstalled torch-2.5.1\n",
            "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: transformers 4.46.2\n",
            "Uninstalling transformers-4.46.2:\n",
            "  Successfully uninstalled transformers-4.46.2\n",
            "Found existing installation: accelerate 1.2.0\n",
            "Uninstalling accelerate-1.2.0:\n",
            "  Successfully uninstalled accelerate-1.2.0\n",
            "Found existing installation: bitsandbytes 0.43.3\n",
            "Uninstalling bitsandbytes-0.43.3:\n",
            "  Successfully uninstalled bitsandbytes-0.43.3\n",
            "Found existing installation: unsloth 2024.11.7\n",
            "Uninstalling unsloth-2024.11.7:\n",
            "  Successfully uninstalled unsloth-2024.11.7\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.1.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m696.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.0+cu121\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (2024.9.0)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0+cu121)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0+cu121) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0+cu121) (1.3.0)\n",
            "Installing collected packages: triton, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.14.0 requires accelerate>=0.21.0, which is not installed.\n",
            "peft 0.14.0 requires transformers, which is not installed.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, which is not installed.\n",
            "trl 0.8.6 requires accelerate, which is not installed.\n",
            "trl 0.8.6 requires transformers>=4.31.0, which is not installed.\n",
            "unsloth-zoo 2024.12.1 requires accelerate>=0.34.1, which is not installed.\n",
            "unsloth-zoo 2024.12.1 requires transformers>=4.46.1, which is not installed.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.1.0+cu121 which is incompatible.\n",
            "xformers 0.0.28.post3 requires torch==2.5.1, but you have torch 2.1.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.0+cu121 torchvision-0.16.0+cu121 triton-2.1.0\n",
            "Collecting transformers==4.46.2\n",
            "  Using cached transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.2) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.2) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.2) (2024.8.30)\n",
            "Using cached transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
            "Installing collected packages: transformers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.14.0 requires accelerate>=0.21.0, which is not installed.\n",
            "trl 0.8.6 requires accelerate, which is not installed.\n",
            "unsloth-zoo 2024.12.1 requires accelerate>=0.34.1, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed transformers-4.46.2\n",
            "Collecting bitsandbytes==0.43.3\n",
            "  Using cached bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.3) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.3) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (2024.9.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes==0.43.3) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes==0.43.3) (1.3.0)\n",
            "Using cached bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.3\n",
            "Collecting unsloth==2024.11.7\n",
            "  Using cached unsloth-2024.11.7-py3-none-any.whl.metadata (59 kB)\n",
            "Requirement already satisfied: unsloth-zoo>=2024.11.1 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (2024.12.1)\n",
            "Collecting torch>=2.4.0 (from unsloth==2024.11.7)\n",
            "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (0.0.28.post3)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (0.43.3)\n",
            "Collecting triton>=3.0.0 (from unsloth==2024.11.7)\n",
            "  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (24.2)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (0.9.2)\n",
            "Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (4.46.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (3.1.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (1.26.4)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (1.2.0)\n",
            "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (0.8.6)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (0.14.0)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (0.26.3)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.11.7) (0.1.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth==2024.11.7) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth==2024.11.7) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.11.7) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.11.7) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.11.7) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.11.7) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.11.7) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.11.7) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.11.7) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth==2024.11.7) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.11.7) (3.11.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth==2024.11.7) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.11.7) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth==2024.11.7) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth==2024.11.7) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth==2024.11.7) (0.20.3)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth==2024.11.7) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth==2024.11.7) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth==2024.11.7) (1.7.1)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth==2024.11.7) (4.4.1)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth==2024.11.7) (24.12.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth==2024.11.7) (11.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.11.7) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.11.7) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.11.7) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.11.7) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.11.7) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.11.7) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.11.7) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.11.7) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth==2024.11.7) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth==2024.11.7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth==2024.11.7) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth==2024.11.7) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth==2024.11.7) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth==2024.11.7) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth==2024.11.7) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth==2024.11.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth==2024.11.7) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth==2024.11.7) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth==2024.11.7) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth==2024.11.7) (1.16.0)\n",
            "Using cached unsloth-2024.11.7-py3-none-any.whl (163 kB)\n",
            "Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "Installing collected packages: triton, torch, unsloth\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.5.1 triton-3.1.0 unsloth-2024.11.7\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: trl<0.9.0 in /usr/local/lib/python3.10/dist-packages (0.8.6)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl<0.9.0) (2.5.1)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl<0.9.0) (4.46.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl<0.9.0) (1.26.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl<0.9.0) (1.2.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl<0.9.0) (3.1.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl<0.9.0) (0.9.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl<0.9.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl<0.9.0) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl<0.9.0) (0.20.3)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<0.9.0) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<0.9.0) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<0.9.0) (1.7.1)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<0.9.0) (4.4.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl<0.9.0) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl<0.9.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl<0.9.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl<0.9.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->trl<0.9.0) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl<0.9.0) (3.11.9)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl<0.9.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl<0.9.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl<0.9.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl<0.9.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl<0.9.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl<0.9.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl<0.9.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl<0.9.0) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl<0.9.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl<0.9.0) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl<0.9.0) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl<0.9.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl<0.9.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl<0.9.0) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl<0.9.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl<0.9.0) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model, LoraConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from trl import PPOTrainer, PPOConfig\n",
        "import torch\n",
        "import random\n",
        "from google.colab import userdata\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "import numpy as np\n",
        "import os\n",
        "from google.cloud import storage\n",
        "from safetensors import safe_open\n",
        "import copy\n",
        "from unsloth import FastLanguageModel\n",
        "from transformers import TextStreamer"
      ],
      "metadata": {
        "id": "1WhARjFnJ8Ck"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulated user profiles and preferences\n",
        "we define a simulated spicy-loving user, who prefers spicy flavors, and a sour-loving user, who prefers sour flavors."
      ],
      "metadata": {
        "id": "QsYMw4YGK4hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_profiles = {\n",
        "    \"spicy_lover\": {\n",
        "        \"preferred_flavor\": \"spicy\",\n",
        "        \"keywords\": [\"spicy\"], #will store keywords that are related to spiciness\n",
        "        \"ingredients\":[\"hot pepper\", \"hot sauce\", \"chili\", \"jalapeno\"]  #will store ingredients that are related to spiciness\n",
        "    },\n",
        "    \"sour_lover\": {\n",
        "        \"preferred_flavor\": \"sour\",\n",
        "        \"keywords\": [\"sour\"], #will store keywords that are related to sourness\n",
        "        \"ingredients\":[\"lime\", \"lemon\", \"vinegar\"]  #will store ingredients that are related to sourness\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "WKEwueuLK96m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwOmJDO7IiFo",
        "outputId": "acdabae7-03d0-467f-becb-fab25a4fdbfa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we enhance the user profiles to include keywords that are synonyms to their preferneces. The synonyms are determined by WordNet."
      ],
      "metadata": {
        "id": "ScCLGeYsIrK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_synonyms_and_related_terms(word):\n",
        "    \"\"\"\n",
        "    Find synonyms and related terms using WordNet\n",
        "    \"\"\"\n",
        "    related_terms = set()\n",
        "    for syn in wn.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            related_terms.add(lemma.name())\n",
        "    return related_terms\n",
        "\n",
        "def enhance_user_profile(user_profile):\n",
        "    \"\"\"\n",
        "    Extend the keywords and ingredients in the user_profile with synonyms\n",
        "    \"\"\"\n",
        "    extended_profile = {\n",
        "        \"keywords\": set(user_profile[\"keywords\"]),\n",
        "        \"ingredients\": set(user_profile[\"ingredients\"])\n",
        "    }\n",
        "\n",
        "    for keyword in user_profile[\"keywords\"]:\n",
        "        # if the keyword has multiple words, join them with _ for nltk recognition\n",
        "        keyword_underscored = keyword.replace(\" \", \"_\") if \" \" in keyword else keyword\n",
        "\n",
        "        related_keywords = get_synonyms_and_related_terms(keyword_underscored)\n",
        "        # join the _ in the related word returned by nltk if the related word has it\n",
        "        related_keywords_clean = [rk.replace(\"_\", \" \") if \"_\" in rk else rk for rk in related_keywords]\n",
        "\n",
        "        extended_profile[\"keywords\"].update(related_keywords_clean)\n",
        "\n",
        "    # Enhance ingredients with related terms\n",
        "    for ingredient in user_profile[\"ingredients\"]:\n",
        "        # if the ingredient has multiple words, join them with _ for nltk recognition\n",
        "        ingredient_underscored = ingredient.replace(\" \", \"_\") if \" \" in ingredient else ingredient\n",
        "\n",
        "        related_ingredients = get_synonyms_and_related_terms(ingredient_underscored)\n",
        "        # join the _ in the related word returned by nltk if the related word has it\n",
        "        related_ingredients_clean = [ri.replace(\"_\", \" \") if \"_\" in ri else ri for ri in related_ingredients]\n",
        "\n",
        "        extended_profile[\"ingredients\"].update(related_ingredients_clean)\n",
        "\n",
        "    extended_profile[\"keywords\"] = list(extended_profile[\"keywords\"])\n",
        "    extended_profile[\"ingredients\"] = list(extended_profile[\"ingredients\"])\n",
        "\n",
        "    return extended_profile\n",
        "\n",
        "for user_type, user_profile in user_profiles.items():\n",
        "    enhanced_profile = enhance_user_profile(user_profile)\n",
        "    user_profile[\"extended_keywords\"] = enhanced_profile[\"keywords\"]\n",
        "    user_profile[\"extended_ingredients\"] = enhanced_profile[\"ingredients\"]"
      ],
      "metadata": {
        "id": "ujqAoVzsIvKo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_profiles.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCqgSFt548ND",
        "outputId": "cbd0cb3e-75c4-4ab3-f6e8-f402cba8c90f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('spicy_lover', {'preferred_flavor': 'spicy', 'keywords': ['spicy'], 'ingredients': ['hot pepper', 'hot sauce', 'chili', 'jalapeno'], 'extended_keywords': ['hot', 'risque', 'racy', 'juicy', 'savoury', 'blue', 'gamey', 'naughty', 'gamy', 'zesty', 'piquant', 'savory', 'spicy'], 'extended_ingredients': ['tabasco plant', 'chile', 'Capsicum annuum longum', 'cayenne', 'chilly', 'chili con carne', 'jalapeno', 'Capsicum frutescens', 'hot sauce', 'cayenne pepper', 'chilli', 'chilli pepper', 'long pepper', 'chili pepper', 'tabasco pepper', 'jalapeno pepper', 'hot pepper', 'chili']}), ('sour_lover', {'preferred_flavor': 'sour', 'keywords': ['sour'], 'ingredients': ['lime', 'lemon', 'vinegar'], 'extended_keywords': ['saturnine', 'off-key', 'ferment', 'morose', 'false', 'glowering', 'sullen', 'off', 'acidity', 'moody', 'acidulate', 'rancid', 'dour', 'dark', 'sour', 'sourness', 'glum', 'tartness', 'turned', 'acetify', 'acidify', 'work', 'turn'], 'extended_ingredients': ['hydrated lime', 'calcium hydroxide', 'lemon tree', 'calcium hydrate', 'lemon yellow', 'burnt lime', 'birdlime', 'lime tree', 'caustic lime', 'slaked lime', 'Citrus limon', 'vinegar', 'unslaked lime', 'acetum', 'lime hydrate', 'basswood', 'maize', 'linden tree', 'calx', 'calcium oxide', 'gamboge', 'Citrus aurantifolia', 'lime', 'calcined lime', 'linden', 'fluxing lime', 'lemon', 'quicklime', 'stinker']})])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(user_profiles.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcHL4J_B5Hr1",
        "outputId": "9cb48c5e-65fd-413a-e3e0-44d8f9ae8229"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['spicy_lover', 'sour_lover']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RLAIF\n",
        "\n",
        "Since we do not have human feedback data, inspired by the work on RLAIF, we use the off-the-shell `llama-3.1-8b-instant` model (called through the GroqAPI) for preference labeling. The model decides from two generated recipes which one better suits the user's taste profile, since DPO instead of PPO will be implemented."
      ],
      "metadata": {
        "id": "daB0vOU26o-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import requests\n",
        "groq_api_key = userdata.get('GROQ_API_KEY')\n",
        "model = 'llama-3.1-8b-instant'\n",
        "client = Groq(\n",
        "      api_key=groq_api_key\n",
        "  )\n",
        "\n",
        "def get_ai_preference(generated_1, generated_2, user_type, user_profile):\n",
        "    \"\"\"\n",
        "    RLAIF - an off-the-shelf LLM labels which recipe aligns better with the user's taste profile.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert chef who understands user's taste profile well.\n",
        "    A {user_type} user prefers recipes with the following characteristics:\n",
        "    - Keywords: {', '.join(user_profile['extended_keywords'])}\n",
        "    - Ingredients: {', '.join(user_profile['extended_ingredients'])}\n",
        "\n",
        "    Based on the user's preferences, which of the two recipes aligns with the taste profile of the user better? Respond with \"Recipe 1\" or \"Recipe 2\" only, no additional tokens.\n",
        "\n",
        "    1. Recipe 1: {generated_1}\n",
        "    2. Recipe 2: {generated_2}\n",
        "    \"\"\"\n",
        "\n",
        "    client = Groq(\n",
        "        api_key=groq_api_key\n",
        "    )\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt,\n",
        "                }\n",
        "            ],\n",
        "        model='llama-3.1-8b-instant'\n",
        "    )\n",
        "    choice_response = chat_completion.choices[0].message.content\n",
        "\n",
        "    # Determine the preferred recipe\n",
        "    if \"Recipe 1\" in choice_response or \"recipe 1\" in choice_response:\n",
        "        return generated_1\n",
        "    elif \"Recipe 2\" in choice_response or \"recipe 2\" in choice_response:\n",
        "        return generated_2\n",
        "    else:\n",
        "        return choice_response"
      ],
      "metadata": {
        "id": "_1nfAWvkoDk-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for user_type, user_profile in user_profiles.items():\n",
        "    # simple generated recipes to demonstrate AIF performance\n",
        "    generated_recipe_1 = \"chili with jalapeno and hot sauce.\"\n",
        "    generated_recipe_2 = \"tomato soup recipe with vinegar.\"\n",
        "    preferred_recipe = get_ai_preference(generated_recipe_1, generated_recipe_2, user_type, user_profile)\n",
        "    print(user_type)\n",
        "    print(\"Preferred Recipe:\", preferred_recipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe9OUDTyozGN",
        "outputId": "5880f784-0610-42c1-a32a-b70b8346394f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spicy_lover\n",
            "Preferred Recipe: chili with jalapeno and hot sauce.\n",
            "sour_lover\n",
            "Preferred Recipe: tomato soup recipe with vinegar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying LoRA to finetuned llama-3.2-3b model"
      ],
      "metadata": {
        "id": "2UmTiVkyLgjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original fine-tuned model"
      ],
      "metadata": {
        "id": "svfFcZiOX2tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llama_checkpoint_path = \"./checkpoint-4512\"  # TO-DO: change this\n",
        "local_file_path=\"./checkpoint-4512/adapter_model.safetensors\"  # TO-DO: change this\n",
        "\n",
        "llama_model, llama_tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=llama_checkpoint_path,\n",
        "    max_seq_length=2048,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "FastLanguageModel.for_inference(llama_model)\n",
        "text_streamer = TextStreamer(llama_tokenizer)\n",
        "\n",
        "state_dict = {}\n",
        "with safe_open(local_file_path, framework=\"pt\", device=\"cpu\") as f:\n",
        "    for key in f.keys():\n",
        "        state_dict[key] = f.get_tensor(key)\n",
        "\n",
        "llama_model.load_state_dict(state_dict, strict=False)\n",
        "llama_model.eval()"
      ],
      "metadata": {
        "id": "xXzJHdVhAWyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DPO model"
      ],
      "metadata": {
        "id": "IA98czcvX39l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dpo_model = copy.deepcopy(llama_model)\n",
        "dpo_tokenizer = llama_tokenizer\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dpo_model.to(device)\n",
        "\n",
        "# apply LoRA to DPO model\n",
        "lora_config = LoraConfig(\n",
        "    r=4,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "dpo_model = get_peft_model(dpo_model, lora_config)\n",
        "dpo_model.print_trainable_parameters()\n",
        "\n",
        "optimizer = torch.optim.AdamW(dpo_model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "g3Oe4JruX2Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop with DPO"
      ],
      "metadata": {
        "id": "r-QmdRsBLQ3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train for 5 epochs with 50 DPO comparisons per epoch."
      ],
      "metadata": {
        "id": "u8U8zelYY8K3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recipe(model, tokenizer, prompt, max_new_tokens=150, stream_output=False, preference=None):\n",
        "    \"\"\"\n",
        "    Generate text using the provided model and tokenizer.\n",
        "    \"\"\"\n",
        "    if preference:\n",
        "        prompt += \"The recipe should have a \" + preference + \" flavor\"\n",
        "\n",
        "    model.to(device)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    if stream_output and text_streamer:\n",
        "        _ = model.generate(\n",
        "            **inputs, streamer=text_streamer, max_new_tokens=max_new_tokens\n",
        "        )\n",
        "        return None\n",
        "    else:\n",
        "        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "ca0xD1xUVqXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_to_same_length(tensor_a, tensor_b, pad_value=0):\n",
        "    \"\"\"\n",
        "    Pad tensors to the same length to facilitate DPO loss calculation\n",
        "    \"\"\"\n",
        "    max_length = max(tensor_a.size(1), tensor_b.size(1))\n",
        "    tensor_a_padded = F.pad(tensor_a, (0, max_length - tensor_a.size(1)), value=pad_value)\n",
        "    tensor_b_padded = F.pad(tensor_b, (0, max_length - tensor_b.size(1)), value=pad_value)\n",
        "    return tensor_a_padded, tensor_b_padded"
      ],
      "metadata": {
        "id": "M-JU-1-IP5Dd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "num_comparisons_per_epoch = 50  # number of DPO comparisons per epoch\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_dpo_loss = 0  # total DPO loss for the epoch\n",
        "\n",
        "    with tqdm(total=num_comparisons_per_epoch * len(user_profiles), desc=f\"Epoch {epoch + 1}\") as pbar:\n",
        "        for _ in range(num_comparisons_per_epoch):\n",
        "          for user_type, user_profile in user_profiles.items():\n",
        "              prompt = \"Please write a low-sodium meal recipe that takes approximately 55 minutes and includes the following ingredients: tomato, beef. The recipe should be formatted with a clear list of ingredients and detailed, step-by-step cooking instructions.\"\n",
        "\n",
        "              # generate two different recipes\n",
        "              generated_spicy = generate_recipe(dpo_model,dpo_tokenizer, prompt, \"spicy\")\n",
        "              generated_light = generate_recipe(dpo_model,dpo_tokenizer,prompt, \"sour\")\n",
        "\n",
        "              # use RLAIF to determine which recipe the user prefers\n",
        "              preferred_output = get_ai_preference(generated_spicy, generated_light, user_type, user_profile)\n",
        "              non_preferred_output = generated_light if preferred_output == generated_spicy else generated_spicy\n",
        "              preferred_input_ids = dpo_tokenizer(preferred_output, return_tensors=\"pt\").input_ids.to(dpo_model.device)\n",
        "              non_preferred_input_ids = dpo_tokenizer(non_preferred_output, return_tensors=\"pt\").input_ids.to(dpo_model.device)\n",
        "\n",
        "              # get log probabilities for both outputs to compute gradients\n",
        "              preferred_output_logits = dpo_model(preferred_input_ids).logits\n",
        "              non_preferred_output_logits = dpo_model(non_preferred_input_ids).logits\n",
        "              preferred_log_probs = preferred_output_logits.log_softmax(dim=-1)\n",
        "              non_preferred_log_probs = non_preferred_output_logits.log_softmax(dim=-1)\n",
        "\n",
        "              # ensure size of tensors (to avoid error)\n",
        "              seq_len = min(preferred_log_probs.size(1), non_preferred_log_probs.size(1))\n",
        "              preferred_log_probs = preferred_log_probs[:, :seq_len, :]\n",
        "              non_preferred_log_probs = non_preferred_log_probs[:, :seq_len, :]\n",
        "\n",
        "              # check vocab size of tensors (to avoid error)\n",
        "              vocab_size = min(preferred_log_probs.size(-1), non_preferred_log_probs.size(-1))\n",
        "              preferred_log_probs = preferred_log_probs[:, :, :vocab_size]\n",
        "              non_preferred_log_probs = non_preferred_log_probs[:, :, :vocab_size]\n",
        "\n",
        "              # calculate DPO loss\n",
        "              dpo_loss = torch.mean(preferred_log_probs - non_preferred_log_probs)\n",
        "\n",
        "              # update model weights\n",
        "              optimizer.zero_grad()\n",
        "              (-dpo_loss).backward()  # Negate to maximize the preference\n",
        "              optimizer.step()\n",
        "\n",
        "              epoch_dpo_loss += dpo_loss.item()\n",
        "\n",
        "              pbar.update(1)\n",
        "              print(f\"++++++++ User Type: {user_type} ++++++++\")\n",
        "              print(f\"++++++++ Prompt: {prompt} ++++++++\")\n",
        "              print(f\"++++++++ Preferred Recipe: {preferred_output} ++++++++\")\n",
        "              print(f\"++++++++ Non-Preferred Recipe: {non_preferred_output} ++++++++\")\n",
        "              print(f\"++++++++ DPO Loss: {dpo_loss.item()} ++++++++\")\n",
        "              print(\"-\" * 80)\n",
        "\n",
        "    # average DPO loss for the epoch\n",
        "    avg_epoch_loss = epoch_dpo_loss / (num_comparisons_per_epoch * len(user_profiles))\n",
        "    print(f\"******* Epoch {epoch + 1} completed with average DPO loss: {avg_epoch_loss:.4f} *******\")\n",
        "    print(\"=\" * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4TNPYPwRaLU",
        "outputId": "4d3c696e-d11a-4430-d968-aa9966eff17e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  50%|█████     | 1/2 [00:21<00:21, 21.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++ User Type: spicy_lover ++++++++\n",
            "++++++++ Prompt: Please write a low-sodium meal recipe that takes approximately 55 minutes and includes the following ingredients: tomato, beef. The recipe should be formatted with a clear list of ingredients and detailed, step-by-step cooking instructions. ++++++++\n",
            "++++++++ Preferred Recipe: and should be formatted with a clear list of ingredients and detailed, step-by-step cooking instructions.Ingredients:\n",
            "tomato\n",
            "beef\n",
            "\n",
            "Instructions:\n",
            "1. put all ingredients in crock pot , add water if necessary , cook on high for 1 hour\n",
            "2. serve over rice or pasta !\n",
            "3. i use my favorite method -- cooked steak or chicken , but you can also substitute veggies like mushrooms or broccoli to get the desired effect\n",
            "4. it is not necessary to use all of the vegetables , just enough to make the meaty texture better than most other types of meats\n",
            "5. you may need to adjust the seasoning a bit depending on your taste -- some people prefer a thicker consistency , others prefer thinner , drier , or even more liquid\n",
            "6. this is okay !\n",
            "7. i've always used a small amount of extra virgin olive oil for the sauce\n",
            "8. it's easier to season with salt and pepper , and makes a pretty good dipping sauce too\n",
            "9. you can also add in garlic powder if you want to spice things up\n",
            "10. it will give the right amount of sweetness for those who don't like spicy , salty flavors\n",
            "11. it also freezes well and is very easy to prepare\n",
            "12. i usually use 2 tablespoons of butter , and then add a little flour , if using , and stir until smooth\n",
            "13. you'll know when its ready , because it doesnt stick together ++++++++\n",
            "++++++++ Non-Preferred Recipe: and was prepared in advance by chef's son, who has also worked on the recipe.Ingredients:\n",
            "tomato\n",
            "beef\n",
            "\n",
            "Instructions:\n",
            "1. combine all ingredients except steak in a bowl\n",
            "2. cover with plastic wrap and refrigerate for several hours or overnight\n",
            "3. serve hot over steamed rice , noodles , and vegetables\n",
            "4. garnish with cheese , salt & pepper to taste\n",
            "5. enjoy ! :)\n",
            "6. can be served warm , cold , or at room temperature , as long as you don't use a stove top\n",
            "7. i prefer it to be served at room temperature , but if you're serving it at room temperature , then sure : )\n",
            "8. you could also put it in the fridge for up to two weeks , but i haven't tried this yet so i cannot say for certain how much longer it will stay in the fridge until it is ready to serve !\n",
            "9. it really does get better after about 3 months in the refrigerator -- just keep checking it !\n",
            "10. i like to add some extra fat when i cook them because they are easier to handle and give me a nice crunchy texture\n",
            "11. i love my hamburger buns with bacon bits sprinkled on top\n",
            "12. i'm sorry you didn't get any suggestions for what to do with these burgers -- i think you could make them pretty similar to stewed tomatoes\n",
            "13. there are many ways to make them better ++++++++\n",
            "++++++++ DPO Loss: -0.2613828778266907 ++++++++\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2/2 [00:40<00:00, 20.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++ User Type: sour_lover ++++++++\n",
            "++++++++ Prompt: Please write a low-sodium meal recipe that takes approximately 55 minutes and includes the following ingredients: tomato, beef. The recipe should be formatted with a clear list of ingredients and detailed, step-by-step cooking instructions. ++++++++\n",
            "++++++++ Preferred Recipe: but is very delicious served on a bed of lettuce or salad greens.Ingredients:\n",
            "tomato\n",
            "beef\n",
            "\n",
            "Instructions:\n",
            "1. cut meat into bite size pieces\n",
            "2. combine all ingredients except lettuce in a blender\n",
            "3. puree until smooth\n",
            "4. serve over your favorite pasta , salad greens or rolls !\n",
            "5. enjoy ! :)\n",
            "6. also great for dipping !\n",
            "7. if you like it to be a little sweeter than that , add more salt and pepper to taste\n",
            "8. i'm not sure how to make this any other way so i substitute vegetable oil instead of water\n",
            "9. you can also use a non stick blender or food processor to make this much easier\n",
            "10. also great for dipping , as well as for sandwiches !\n",
            "11. i love to dip my sandwich in some of these ! they're just wonderful !\n",
            "12. yum ! ! i'm sorry i don't have an alternative for this recipe : /\n",
            "13. i think it's better without the vegetables , because the flavors are quite different\n",
            "14. i've never tried adding them together before , though -- i always just toss the veggies in a bowl\n",
            "15. they do get a bit \"shredded\" when you put them in the blender\n",
            "16. you could add some chopped tomatoes , too , if you want\n",
            "17. i think this is a pretty good substitute for chicken soup , although i haven't tested ++++++++\n",
            "++++++++ Non-Preferred Recipe: but is also light in color and chewy so you can eat it hot or cold\n",
            "\n",
            "Instructions:\n",
            "1. cook meat according to package directions , drain well and set aside\n",
            "2. brown beef in large skillet on medium heat\n",
            "3. add tomato , diced onion and remaining ingredients\n",
            "4. bring to boil , reduce heat to low and simmer for 20 minute or until meat tenderens\n",
            "5. serve warm or chilled with rice or couscous , if desired !\n",
            "6. this dish is great served over rice or couscous as an appetizer !\n",
            "7. i like to use my pasta as a dip , and place it on top of me , then sprinkle with some fresh parsley or garlic , if you like it spicy\n",
            "8. it's delicious cooked and served with rice or couscous !\n",
            "9. just enjoy ! :)\n",
            "10. your family will love this ! :)\n",
            "11. it is very yummy ! i'm sure there are people who would love this too ! :)\n",
            "12. try it ! it tastes better when it is added immediately after you add it ! and it has lots of calories ! :) :)\n",
            "13. i think that this dish is best served the day before !\n",
            "14. it makes the perfect appetizer ! :)\n",
            "15. it is great leftovers !\n",
            "16. it's a nice dessert !\n",
            "17. it is so easy to make these and they are very tasty ! :) ++++++++\n",
            "++++++++ DPO Loss: 0.15710359811782837 ++++++++\n",
            "--------------------------------------------------------------------------------\n",
            "******* Epoch 1 completed with average DPO loss: -0.0521 *******\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare Original vs. RLAIF model"
      ],
      "metadata": {
        "id": "ONs9e2tiNfsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def format_recipe(recipe_text):\n",
        "    \"\"\"\n",
        "    Format a recipe string into HTML.\n",
        "    \"\"\"\n",
        "    parts = recipe_text.split(\"Instructions:\")\n",
        "    #ingredients = parts[0].replace(\"Ingredients:\", \"\").strip().split(\"\\n\")\n",
        "    instructions = parts[1].strip().split(\"\\n\") if len(parts) > 1 else []\n",
        "\n",
        "    #ingredients_html = \"<ul>\" + \"\".join(f\"<li>{ingredient.strip()}</li>\" for ingredient in ingredients if ingredient.strip()) + \"</ul>\"\n",
        "    instructions_html = \"<ol>\" + \"\".join(f\"<li>{instruction.strip()}</li>\" for instruction in instructions if instruction.strip()) + \"</ol>\"\n",
        "\n",
        "    #return f\"<strong>Ingredients:</strong>{ingredients_html}<strong>Instructions:</strong>{instructions_html}\"\n",
        "    return f\"<strong>Instructions:</strong>{instructions_html}\"\n",
        "\n",
        "\n",
        "def display_model_comparison():\n",
        "    prompt = \"Please write a low-sodium meal recipe that takes approximately 55 minutes and includes the following ingredients: tomato, beef. The recipe should be formatted with a clear list of ingredients and detailed, step-by-step cooking instructions.\"\n",
        "    user_specifics = []\n",
        "    rlaif_outputs = []\n",
        "    original_outputs = []\n",
        "\n",
        "    for user_type, user_profile in user_profiles.items():\n",
        "      flavor = user_profile['preferred_flavor']\n",
        "      original_output = generate_recipe(llama_model, llama_tokenizer, prompt, flavor)\n",
        "      dpo_output = generate_recipe(dpo_model, dpo_tokenizer, prompt, flavor)\n",
        "\n",
        "      user_specifics.append(user_type)\n",
        "      rlaif_outputs.append(format_recipe(dpo_output))\n",
        "      original_outputs.append(format_recipe(original_output))\n",
        "\n",
        "    data = {\n",
        "        \"User specifics\": user_specifics,\n",
        "        \"RLAIF Model Output\": rlaif_outputs,\n",
        "        \"Original Model Output\": original_outputs\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    display(HTML(df.to_html(index=False, escape=False)))\n",
        "\n",
        "display_model_comparison()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Eu0qZpZR4JQn",
        "outputId": "0e15e3fc-5a19-4071-fd46-538332dc18bf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>User specifics</th>\n",
              "      <th>RLAIF Model Output</th>\n",
              "      <th>Original Model Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>spicy_lover</td>\n",
              "      <td><strong>Instructions:</strong><ol><li>1. combine all ingredients , except beef , in crockpot</li><li>2. cook over medium heat until meat is tender</li><li>3. stir in remaining ingredients</li><li>4. cover and simmer for 15 minutes</li><li>5. serve hot or cold</li><li>6. this can also be served as a side dish !</li><li>7. enjoy ! :)</li><li>8. i love to add garlic cloves during the cooking process so they get a bit crispy after you add them</li><li>9. if you like it a little different then just toss in some ground black pepper</li><li>10. i use my crock pot for smoking , but it's not perfect for serving</li><li>11. it does make it easier to clean up the mess when you're done ! :)</li><li>12. i always put the beef in the crockpot before adding the tomatoes and it makes a big difference !</li><li>13. if you don't know what to do with the sauce , use a little more water and let it boil down a bit</li><li>14. it will be thicker and slightly bubbly</li><li>15. if you want it more spicy , add more pepper or salt</li><li>16. it's really simple , and it gives the best result !</li><li>17. try using the fresh thyme or sage</li><li>18. it has a lot of health benefits</li><li>19. you</li></ol></td>\n",
              "      <td><strong>Instructions:</strong><ol><li>1. mix all ingredients together</li><li>2. cook on high for 6 hours or until done to your liking</li><li>3. enjoy !</li><li>4. if you want to add more seasoning , put in a blender or food processor and blend until smooth</li><li>5. serve over rice or noodles !</li><li>6. enjoy !</li><li>7. i always use the same 1 / 4 cup water as it is for this recipe but i like my beans very much</li><li>8. they are also great as an added addition to pasta or chicken soup</li><li>9. i usually just add some chopped tomatoes to taste so they don't get too dry or mushy</li><li>10. i also add a little fresh garlic powder to taste as well</li><li>11. i think this is really good served with plain bread ! :)</li><li>12. i'm sure there will be plenty other variations of this recipe that would make this dish better than it is ! :)</li><li>13. enjoy ! :)</li><li>14. this makes about 2 dozen servings</li><li>15. the original recipe called for 3 cups of meatballs</li><li>16. i used 3 cups of meatballs instead of the original 5 cups because i was afraid they wouldn't be enough</li><li>17. this is what i did and it turned out pretty good</li><li>18. i love serving this with cornbread or a loaf of bread -- both wonderful !</li><li>19. if you</li></ol></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>sour_lover</td>\n",
              "      <td><strong>Instructions:</strong><ol><li>1. combine all ingredients in crockpot , mix well</li><li>2. cover and cook on high for 30 mins</li><li>3. serve hot with crackers , chips or any other kind of cracker you want !</li><li>4. if you don't like them , use another cracker / chip maker ! :)</li><li>5. i always add more water as i go along so it doesn't boil too much</li><li>6. also makes a nice little snack bowl , if you're looking for something sweet take a tablespoon out of your mouth and squeeze some lemon juice into it ! :)</li><li>7. enjoy ! :)</li><li>8. my favorite is an old fashioned , it's great when you're hungry !</li><li>9. this will keep up to 4 months at least !</li><li>10. also good with ice cream !</li><li>11. also great with chocolate ice cream !</li><li>12. also great with brownies !</li><li>13. try it with buttercream , it tastes best with melted buttercream</li><li>14. i've never tried it with crackers , but i'm sure you could get away with it ! :)</li><li>15. if you'd like to substitute any other type of cheese you can use a few different cheeses , such as white bread , egg yolks , black pepper , etc</li><li>16. you'll probably need to adjust the amounts depending on</li></ol></td>\n",
              "      <td><strong>Instructions:</strong><ol><li>1. put all in a bowl</li><li>2. stir together well</li><li>3. refrigerate for several hours , stirring occasionally to ensure even mixing</li><li>4. serve immediately or freeze for up to 1 week !</li><li>5. i like to add frozen chopped tomatoes when they are ready so i can get them out of my fridge overnight !</li><li>6. if you do not have a freezer , just use your favorite food processor to process the tomato into a paste</li><li>7. it will become very dry after this process but you will need to keep it warm in the refrigerator</li><li>8. also make sure to mix thoroughly as it is quite difficult to remove from the heat</li><li>9. if using fresh mushrooms , add a little water to help dissolve any lumps</li><li>10. mix well</li><li>11. let stand at room temperature until fully set</li><li>12. preheat oven to 350 degrees fahrenheit</li><li>13. place the meat on a baking sheet and bake for 30 minutes , then turn the meat over once again</li><li>14. cool the meat completely on a rack before cutting into squares or slices</li><li>15. cut each square into a circle about 3 / 4 inch thick</li><li>16. divide the meat pieces evenly among the squares</li><li>17. slice the squares into quarters</li><li>18. place one piece of bread in each quarter and roll each round around with a fork</li><li>19. cover with plastic wrap and chill for 10 minutes</li><li>20</li></ol></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdLV_wzT9fyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}