{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90c6b025-0feb-4f3c-b8a4-ad2d6b1f9280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2c359b7-13e6-4d48-981f-6627841c1d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Output directory:\n",
      "gs://ai-recipe-trainer/aiplatform-custom-training-2024-11-16-08:17:15.286 \n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/1696065783278338048?project=931474123000\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/8376029930575626240?project=931474123000\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob run completed. Resource name: projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048\n",
      "Training did not produce a Managed Model returning None. Training Pipeline projects/931474123000/locations/us-central1/trainingPipelines/1696065783278338048 is not configured to upload a Model. Create the Training Pipeline with model_serving_container_image_uri and model_display_name passed in. Ensure that your training script saves to model to os.environ['AIP_MODEL_DIR'].\n"
     ]
    }
   ],
   "source": [
    "project = \"ai-recipe-441518\"\n",
    "\n",
    "container_image_uri = f\"gcr.io/{project}/llm-finetuner:v1\"\n",
    "location = \"us-central1\"\n",
    "\n",
    "aiplatform.init(project=project, location=location, staging_bucket=\"gs://ai-recipe-trainer\")\n",
    "\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=\"llama_3b_finetuning\",\n",
    "    container_uri = container_image_uri,\n",
    "    project = project,\n",
    "    location = location\n",
    ")\n",
    "\n",
    "replica_count = 1\n",
    "machine_type = \"n1-standard-8\"\n",
    "accelerator_type = \"NVIDIA_TESLA_T4\"\n",
    "accelerator_count = 1\n",
    "\n",
    "job.run(\n",
    "    replica_count = replica_count,\n",
    "    machine_type = machine_type,\n",
    "    accelerator_type = accelerator_type,\n",
    "    accelerator_count = accelerator_count,\n",
    "    sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c49d29-2473-4406-ace1-074de93838f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Output directory:\n",
      "gs://ai-recipe-trainer/aiplatform-custom-training-2024-11-16-08:34:53.214 \n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6536309482794778624?project=931474123000\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/6536309482794778624 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/2985221176613142528?project=931474123000\n",
      "CustomContainerTrainingJob projects/931474123000/locations/us-central1/trainingPipelines/6536309482794778624 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "# GCP project where the serverless training job will run\n",
    "project = \"ai-recipe-441518\"\n",
    "\n",
    "#Defining the container image URI to be used for training\n",
    "container_image_uri = f\"gcr.io/{project}/llm-finetuner:v1\"\n",
    "location = \"us-central1\"\n",
    "\n",
    "# Initialize AI Platform with a staging bucket\n",
    "aiplatform.init(project=project, location=location, staging_bucket=\"gs://ai-recipe-trainer\")\n",
    "\n",
    "# Create a custom container training job\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=\"llama_3b_finetuning\",\n",
    "    container_uri = container_image_uri,\n",
    "    project = project,\n",
    "    location = location\n",
    ")\n",
    "\n",
    "# Specify the configuration for the training job\n",
    "replica_count = 1\n",
    "machine_type = \"n1-standard-8\"\n",
    "accelerator_type = \"NVIDIA_TESLA_T4\"\n",
    "accelerator_count = 1\n",
    "\n",
    "# Start the training job with the specified configuration\n",
    "job.run(\n",
    "    replica_count = replica_count,\n",
    "    machine_type = machine_type,\n",
    "    accelerator_type = accelerator_type,\n",
    "    accelerator_count = accelerator_count,\n",
    "    sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2244f1-0ea0-4725-92e4-337bbb3b7587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
